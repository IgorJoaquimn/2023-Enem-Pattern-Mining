{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquino/UFMG/6-Periodo/MineracaoDeDados/2023-Enem-Pattern-Mining/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numba import jit\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures\n",
    "\n",
    "import swifter\n",
    "from swifter import set_defaults\n",
    "set_defaults(\n",
    "    progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "PATH = \"microdados_enem_2022/DADOS/\"\n",
    "PATH_PROCESSED = \"dados_processados/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv(PATH + \"ITENS_PROVA_2022.csv\",encoding=\"latin\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_azul = questions[questions[\"TX_COR\"] == \"AZUL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hab_questionary = pd.read_csv(PATH + \"QUEST_HAB_ESTUDO.csv\",encoding=\"latin\",sep=\";\", nrows=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_features = [\"NU_INSCRICAO\", \"TX_RESPOSTAS_CN\",\"TX_RESPOSTAS_CH\",\"TX_RESPOSTAS_LC\",\"TX_RESPOSTAS_MT\",'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n",
    "       'CO_PROVA_MT']\n",
    "\n",
    "values_to_match = {\n",
    "    'CO_PROVA_CN': 1085,\n",
    "    'CO_PROVA_CH': 1055,\n",
    "    'CO_PROVA_LC': 1065,\n",
    "    'CO_PROVA_MT': 1075,\n",
    "}\n",
    "answers_features = questions_features[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito_CN = prova_azul[prova_azul[\"CO_PROVA\"] == values_to_match['CO_PROVA_CN']].sort_values(by='CO_POSICAO')[\"TX_GABARITO\"]\n",
    "gabarito_CH = prova_azul[prova_azul[\"CO_PROVA\"] == values_to_match['CO_PROVA_CH']].sort_values(by='CO_POSICAO')[\"TX_GABARITO\"]\n",
    "gabarito_LC = prova_azul[(prova_azul[\"CO_PROVA\"] == values_to_match['CO_PROVA_LC']) & (prova_azul[\"TP_LINGUA\"] != 1)].sort_values(by='CO_POSICAO')[\"TX_GABARITO\"]\n",
    "gabarito_MT = prova_azul[prova_azul[\"CO_PROVA\"] == values_to_match['CO_PROVA_MT']].sort_values(by='CO_POSICAO')[\"TX_GABARITO\"]\n",
    "\n",
    "gabaritos = [gabarito_CN, gabarito_CH, gabarito_LC, gabarito_MT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to pre_process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_strings(string):\n",
    "    return np.array(list(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(feature):\n",
    "        i,area,microdados,gabaritos = feature\n",
    "        respostas = microdados[area]\n",
    "        vectorized_resps   = respostas.swifter.apply(vectorize_strings)\n",
    "        right_wrong_corr   = vectorized_resps.swifter.apply(lambda x: x == gabaritos[i])\n",
    "        vectorized_resps[\"NU_INCRICAO\"] = microdados[\"NU_INSCRICAO\"]\n",
    "        right_wrong_corr[\"NU_INCRICAO\"] = microdados[\"NU_INSCRICAO\"]\n",
    "        right_wrong_corr.to_csv(PATH_PROCESSED + \"\" + area + \".csv\",sep=\";\",mode='a')\n",
    "        vectorized_resps.to_csv(PATH_PROCESSED + \"Vectorized_\" + area + \".csv\",sep=\";\",mode='a')\n",
    "\n",
    "def get_gabaritos(answers_features,microdados,gabaritos):\n",
    "    values = list(enumerate(answers_features))\n",
    "    values = [x + (microdados,gabaritos) for x in values]\n",
    "    with Pool() as pool:\n",
    "        pool.map(task,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk):\n",
    "    microdados = chunk[questions_features].dropna()\n",
    "    microdados_azul = microdados[(microdados['CO_PROVA_MT'] == values_to_match['CO_PROVA_MT'])]\n",
    "    get_gabaritos(answers_features[:-4],microdados_azul,gabaritos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processamento dos microdados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "num_workers = 100\n",
    "microdados_reader = pd.read_csv(PATH + \"MICRODADOS_ENEM_2022.csv\",encoding=\"latin\",sep=\";\",chunksize=N)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Use the executor to process each chunk in parallel\n",
    "    futures = [executor.submit(process_chunk, chunk) for chunk in microdados_reader]\n",
    "\n",
    "    # Wait for all processing tasks to complete\n",
    "    concurrent.futures.wait(futures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
